{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 아이펠톤에서 사용할 데이터 생성하는 노트북\n",
    "\n",
    "### 발생한 이슈\n",
    "- 필수 문장 체크하는 코드를 이곳 저곳에서 사용할 것 같음 \n",
    "- class로 만들어서 재활용 가능하게 만들어봄\n",
    "\n",
    "### 코드 흐름\n",
    "1. 필수 문장 잘 포함하고 있는지 평가하는 부분의 코드 작성\n",
    "    - 필수 문장 (thought)가 잘 들어 있는가? - 중복된 단어 수 + 거리\n",
    "    - 생성된 여러 데이터셋에 공통된 표현이 존재하는가? - 중복 문장 비교\n",
    "2. 기존에 만든 C2D2 데이터셋을 위 기준으로 변경하여 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from difflib import SequenceMatcher\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 문장이 잘 들어 있는가? \n",
    "## 필수 문장 내 단어와 story의 문장 중에 단어가 겹치는 % 비율 계산\n",
    "## Longest Common Subsequence(LCS, 최장 공통 부분 문자열) 알고리즘을 사용하여 문장 유사도 측정\n",
    "\n",
    "class instruct_check_sentence_include:\n",
    "    # x = 데이터프레임\n",
    "    # compare_column = 비교할 문장 컬럼명 텍스트\n",
    "    # phragraph = 비교할 문단 컬럼명 텍스트\n",
    "    def __init__(self, x, compare_column, phragraph):\n",
    "        self.data = x\n",
    "        self.data[\"compare_sentences\"] = self.data[compare_column].str.replace(', ', '. ', case=False)\n",
    "        self.data[\"compare_sentences\"] = self.data[\"compare_sentences\"].apply(lambda x: nltk.sent_tokenize(x))\n",
    "        \n",
    "        self.data[\"phragraph_sentences\"] = self.data[phragraph].str.replace(', ', '. ', case=False)\n",
    "        self.data[\"phragraph_sentences\"] = self.data[\"phragraph_sentences\"].apply(lambda x: nltk.sent_tokenize(x))\n",
    "\n",
    "    ## 필수 문장 내 단어와 story의 문장 중에 단어가 겹치는 % 비율 계산\n",
    "    ### 문장 부호를 제거한 후, 소문자로 변환하고 단어로 분리하는 함수\n",
    "    def clean_and_split(self, sentence):\n",
    "        # 문장 부호 제거 (string.punctuation을 사용하여 기본적인 문장 부호 제거)\n",
    "        cleaned_sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "                \n",
    "        # 소문자로 변환하고 단어로 분리\n",
    "        words = cleaned_sentence.lower().split()\n",
    "        \n",
    "        return words\n",
    "\n",
    "    ### 두 문장 간의 공통 단어 비율을 계산하는 함수\n",
    "    def partial_inclusion_ratio(self, compare_sentence, phragraph) :\n",
    "        # 두 문장을 단어로 분리\n",
    "        compare_words = list(self.clean_and_split(compare_sentence))\n",
    "        phragraph_words = list(self.clean_and_split(phragraph))\n",
    "\n",
    "        # 공통 문자를 찾기 위해 base_sentence의 문자들이 sentence에 얼마나 포함되는지 확인\n",
    "        common_words = [word for word in compare_words if word in phragraph_words]\n",
    "        \n",
    "        # 포함된 문자 비율을 계산\n",
    "        if len(common_words) == 0:\n",
    "            inclusion_ratio = 0\n",
    "        else:\n",
    "            inclusion_ratio = len(common_words) / len(compare_words)\n",
    "        \n",
    "        return round(inclusion_ratio, 2)\n",
    "    \n",
    "    ## Longest Common Subsequence(LCS, 최장 공통 부분 문자열) 알고리즘을 사용하여 문장 유사도 측정\n",
    "    def similar(self, a, b):\n",
    "        return round(SequenceMatcher(None, a, b).ratio(), 2)\n",
    "    \n",
    "    ### 각 row의 모든 문장 쌍에 대해 유사도를 계산하는 함수\n",
    "    def calculate_all_ratios(self):\n",
    "        # 새로운 리스트에 각 row에 대해 유사도를 저장\n",
    "        compare_sentences_list = [] # 포함되어야 하는 문장\n",
    "        phragraph_sentences_list = [] # 공통단어비율 계산할 story 문장\n",
    "        row_similarity_ratios = []\n",
    "        min_ratios = []\n",
    "        \n",
    "        phragraph_LCS_sentences_list = []\n",
    "        row_LCS_similarity_ratios = []\n",
    "        min_LCS_ratios = []\n",
    "        \n",
    "        final_p_sen_list = []\n",
    "        final_max_ratio_list = []\n",
    "        final_min_ratio = []\n",
    "        \n",
    "        for index, row in self.data.iterrows():\n",
    "            compare_sentences = row['compare_sentences']\n",
    "            phragraph_sentences = row['phragraph_sentences']\n",
    "            \n",
    "            # 각 문장 쌍에 대해 partial_inclusion_ratio 계산\n",
    "            c_list = []\n",
    "            p_list = []\n",
    "            row_ratios = []\n",
    "            LCS_p_list = []\n",
    "            LCS_row_ratios = []\n",
    "            final_p_list = []\n",
    "            final_max_ratios = []\n",
    "            \n",
    "            for compare_sentence in compare_sentences:\n",
    "                max_ratio = 0\n",
    "                p_sen = ''\n",
    "                max_LCS_ratio = 0\n",
    "                LCS_p_sen = ''\n",
    "                final_p_sen = ''\n",
    "                final_max_ratio = 0\n",
    "                \n",
    "                # 문장이 너무 짧으면 비교하지 않음\n",
    "                if len(compare_sentence) <= 2:\n",
    "                    continue\n",
    "                \n",
    "                for phragraph_sentence in phragraph_sentences:\n",
    "                    # 문장이 포함관계이면, 공통 단어 비율을 1로 저장\n",
    "                    clean_c_sen = compare_sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "                    clean_p_sen = phragraph_sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "                    \n",
    "                    if clean_c_sen in clean_p_sen or clean_p_sen in clean_c_sen:\n",
    "                        max_ratio = 1.0\n",
    "                        p_sen = phragraph_sentence\n",
    "                        # continue\n",
    "                    else:\n",
    "                        # 공통 단어 비율 계산\n",
    "                        ratio = self.partial_inclusion_ratio(compare_sentence, phragraph_sentence)\n",
    "\n",
    "                        if ratio > max_ratio: \n",
    "                            max_ratio = ratio\n",
    "                            p_sen = phragraph_sentence\n",
    "                        \n",
    "                    # LCS 관점의 유사도 계산\n",
    "                    LCS_ratio = self.similar(compare_sentence, phragraph_sentence)\n",
    "                    \n",
    "                    # LCS 유사도가 더 높으면 업데이트\n",
    "                    if LCS_ratio > max_LCS_ratio:\n",
    "                        max_LCS_ratio = LCS_ratio\n",
    "                        LCS_p_sen = phragraph_sentence\n",
    "                        \n",
    "                    # 최종 문장 저장\n",
    "                    if max_ratio >= max_LCS_ratio:\n",
    "                        final_p_sen = p_sen\n",
    "                    else:\n",
    "                        final_p_sen = LCS_p_sen\n",
    "                        \n",
    "                    # 최종 유사도 저장\n",
    "                    if max_ratio >= max_LCS_ratio:\n",
    "                        final_max_ratio = max_ratio\n",
    "                    else:\n",
    "                        final_max_ratio = max_LCS_ratio\n",
    "                    \n",
    "                c_list.append(compare_sentence) # 필수 비교 문장 저장\n",
    "                p_list.append(p_sen) # 공통단어비율 문장 저장\n",
    "                row_ratios.append(max_ratio) # 공통단어비율 저장\n",
    "                LCS_p_list.append(LCS_p_sen) # LCS 문장 저장\n",
    "                LCS_row_ratios.append(max_LCS_ratio) # LCS 저장\n",
    "                final_p_list.append(final_p_sen) # 최종 문장 저장\n",
    "                final_max_ratios.append(final_max_ratio) # 최종 유사도 저장\n",
    "                    \n",
    "            # 한 row에서 가장 높은 유사도 문장과, 가장 낮은 유사도 저장\n",
    "            compare_sentences_list.append(c_list)\n",
    "            phragraph_sentences_list.append(p_list)\n",
    "            row_similarity_ratios.append(row_ratios)\n",
    "            min_ratios.append(min(row_ratios) if row_ratios else 0)\n",
    "            phragraph_LCS_sentences_list.append(LCS_p_list)\n",
    "            row_LCS_similarity_ratios.append(LCS_row_ratios)\n",
    "            min_LCS_ratios.append(min(LCS_row_ratios) if LCS_row_ratios else 0)\n",
    "            final_p_sen_list.append(final_p_list)\n",
    "            final_max_ratio_list.append(final_max_ratios)\n",
    "            final_min_ratio.append(min(final_max_ratios) if final_max_ratios else 0)\n",
    "\n",
    "        # 데이터프레임에 결과 추가\n",
    "        self.data['compare_sentences'] = compare_sentences_list\n",
    "        self.data['phragraph_sentences'] = phragraph_sentences_list\n",
    "        self.data['공통단어비율'] = row_similarity_ratios\n",
    "        self.data['min_공통단어비율'] = min_ratios\n",
    "        self.data['LCS_sentences'] = phragraph_LCS_sentences_list\n",
    "        self.data['LCS_유사도'] = row_LCS_similarity_ratios\n",
    "        self.data['min_LCS_유사도'] = min_LCS_ratios\n",
    "        self.data['final_p_sen'] = final_p_sen_list\n",
    "        self.data['final_max_ratio'] = final_max_ratio_list\n",
    "        self.data['final_min_ratio'] = final_min_ratio\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>Distorted part</th>\n",
       "      <th>label</th>\n",
       "      <th>Distorted_문장분리</th>\n",
       "      <th>Distorted_문장유사도</th>\n",
       "      <th>Distorted_문장유사도평균</th>\n",
       "      <th>기존데이터_scenario</th>\n",
       "      <th>기존데이터_thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm an introverted person, and I've just arriv...</td>\n",
       "      <td>['Are the people in this environment unfriendl...</td>\n",
       "      <td>Overgeneralization</td>\n",
       "      <td>['Are the people in this environment unfriendl...</td>\n",
       "      <td>[100.0]</td>\n",
       "      <td>100.0</td>\n",
       "      <td>I'm an introverted person, and I've just arriv...</td>\n",
       "      <td>Are the people in this environment unfriendly?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  I'm an introverted person, and I've just arriv...   \n",
       "\n",
       "                                      Distorted part               label  \\\n",
       "0  ['Are the people in this environment unfriendl...  Overgeneralization   \n",
       "\n",
       "                                      Distorted_문장분리 Distorted_문장유사도  \\\n",
       "0  ['Are the people in this environment unfriendl...         [100.0]   \n",
       "\n",
       "   Distorted_문장유사도평균                                     기존데이터_scenario  \\\n",
       "0              100.0  I'm an introverted person, and I've just arriv...   \n",
       "\n",
       "                                    기존데이터_thought  \n",
       "0  Are the people in this environment unfriendly?  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv(\"data/c2d2_0924_final.csv\")\n",
    "raw.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = instruct_check_sentence_include(raw, '기존데이터_thought', 'story')\n",
    "\n",
    "a.calculate_all_ratios().to_csv(\"data/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생성된 데이터셋에 공통된 문장 표현이 존재하는가? - 중복 문장 비교\n",
    "\n",
    "# 코드 흐름\n",
    "- 완성된 데이터셋, story 컬럼 입력\n",
    "- story 컬럼 내 모든 텍스트를 가져와서 문장으로 분리 (, )는 (. )으로 바꿔서 더 잘게 나눌 것\n",
    "- 문장 별 count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터 프레임의 story 컬럼에서 문장을 추출하고, 빈도를 계산하는 함수\n",
    "def count_common_sentences(df, story_column, clean = False):\n",
    "    # 모든 story 컬럼의 텍스트를 가져옴\n",
    "    all_sentences = []\n",
    "    \n",
    "    for story in df[story_column]:\n",
    "        if clean:\n",
    "            # , 를 . 로 바꿔서 문장을 더 잘게 나눔\n",
    "            story = story.replace(', ', '. ')\n",
    "        \n",
    "        # 문장을 분리 (원문 그대로)\n",
    "        sentences = nltk.sent_tokenize(story)\n",
    "        \n",
    "        # 모든 문장을 리스트에 추가\n",
    "        all_sentences.extend(sentences)\n",
    "    \n",
    "    # 각 문장의 빈도 계산\n",
    "    sentence_counts = Counter(all_sentences)\n",
    "    \n",
    "    # 빈도별로 내림차순 정렬된 결과 반환\n",
    "    return sentence_counts.most_common()\n",
    "\n",
    "# 공통 문장에서 필수 문장 제거 함수\n",
    "def exclude_should_thought(common_sentences, should_sentences):\n",
    "    # should_thought의 문장만 추출\n",
    "    should_thought_sentences = {sentence for sentence, _ in should_sentences}\n",
    "    \n",
    "    # common_sentences에서 should_thought에 없는 문장만 필터링\n",
    "    filtered_common_sentences = [(sentence, count) for sentence, count in common_sentences if sentence not in should_thought_sentences]\n",
    "    \n",
    "    return filtered_common_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>Distorted part</th>\n",
       "      <th>label</th>\n",
       "      <th>Distorted_문장분리</th>\n",
       "      <th>Distorted_문장유사도</th>\n",
       "      <th>Distorted_문장유사도평균</th>\n",
       "      <th>기존데이터_scenario</th>\n",
       "      <th>기존데이터_thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm an introverted person, and I've just arriv...</td>\n",
       "      <td>['Are the people in this environment unfriendl...</td>\n",
       "      <td>Overgeneralization</td>\n",
       "      <td>['Are the people in this environment unfriendl...</td>\n",
       "      <td>[100.0]</td>\n",
       "      <td>100.0</td>\n",
       "      <td>I'm an introverted person, and I've just arriv...</td>\n",
       "      <td>Are the people in this environment unfriendly?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story  \\\n",
       "0  I'm an introverted person, and I've just arriv...   \n",
       "\n",
       "                                      Distorted part               label  \\\n",
       "0  ['Are the people in this environment unfriendl...  Overgeneralization   \n",
       "\n",
       "                                      Distorted_문장분리 Distorted_문장유사도  \\\n",
       "0  ['Are the people in this environment unfriendl...         [100.0]   \n",
       "\n",
       "   Distorted_문장유사도평균                                     기존데이터_scenario  \\\n",
       "0              100.0  I'm an introverted person, and I've just arriv...   \n",
       "\n",
       "                                    기존데이터_thought  \n",
       "0  Are the people in this environment unfriendly?  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv(\"data/c2d2_0924_final.csv\")\n",
    "raw.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수로 포함해야 하는 문장 추출\n",
    "should_thought = count_common_sentences(raw, '기존데이터_thought',False)\n",
    "clean_should_thought = count_common_sentences(raw, '기존데이터_thought',True)\n",
    "\n",
    "should_scenario = count_common_sentences(raw, '기존데이터_scenario',False)\n",
    "clean_should_scenario = count_common_sentences(raw, '기존데이터_scenario',True)\n",
    "\n",
    "# 생성한 텍스트들에서 공통 문장 추출\n",
    "common_sentences = count_common_sentences(raw, 'story', False)\n",
    "clean_common_sentences = count_common_sentences(raw, 'story', True)\n",
    "\n",
    "# 생성한 텍스트 공통 문장 - 필수로 포함해야 하는 문장\n",
    "filtered_common_sentences = exclude_should_thought(common_sentences, should_thought)\n",
    "filtered_common_sentences = exclude_should_thought(filtered_common_sentences, should_scenario)\n",
    "\n",
    "filtered_clean_common_sentences = exclude_should_thought(clean_common_sentences, clean_should_thought)\n",
    "filtered_clean_common_sentences = exclude_should_thought(filtered_clean_common_sentences, clean_should_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_01 = pd.DataFrame(common_sentences, columns=['gen_공통문장', 'Count'])\n",
    "tmp_02 = pd.DataFrame(should_thought, columns=['thought_공통문장', 'Count'])\n",
    "tmp_03 = pd.DataFrame(should_scenario, columns=['scenario_공통문장', 'Count'])\n",
    "tmp_04 = pd.DataFrame(filtered_common_sentences, columns=['filtered_공통문장', 'Count'])\n",
    "\n",
    "# 데이터프레임 위아래로 합치기\n",
    "sentence_df = pd.concat([tmp_01, tmp_02, tmp_03, tmp_04], axis=1)\n",
    "\n",
    "# 저장할 CSV 파일 이름\n",
    "file_name = 'data/test2.csv'\n",
    "\n",
    "# CSV 파일로 저장\n",
    "sentence_df.to_csv(file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
