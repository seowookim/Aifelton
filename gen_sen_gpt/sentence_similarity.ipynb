{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장 유사도를 여러 방식으로 비교\n",
    "\n",
    "### 발생한 이슈\n",
    "- 같은 텍스트를 넣었는데, openai api에서 포함해야 하는 텍스트를 제외하는 일이 발생함 -> 문장유사도를 판단하여, 유사한 문장을 포함하지 않으면 제외하는 방식 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# NLTK 패키지에서 Punkt tokenizer를 다운로드 (한 번만 실행)\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 레벤슈타인 거리 방식으로 유사도를 판단\n",
    "\n",
    "**레벤슈타인 거리(Levenshtein distance)**는 두 문자열 사이의 차이를 측정하는 방법 중 하나로, 한 문자열을 다른 문자열로 변환하는 데 필요한 편집 작업의 최소 개수를 계산합니다. 이 편집 작업에는 삽입, 삭제, 대체가 포함됩니다.\n",
    "\n",
    "- 아래에서 사용된 데이터는 2개 문장을 이용하여 생성한 것으로, 랜덤 샘플링하여 확인했을때 잘 만들었다고 느껴졌었음\n",
    "- 문장 유사도가 어느정도 되어야 하는지 확인하는데 사용함\n",
    "- 결론 : 0.6 정도는 되야 쓸만함 -> 0.6 미만인 문장이 존재한다면 필터링 할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장유사도 비교\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "# '포함해야 하는 문장들' 내의 1개의 문장과 '만들어진 장문' 내 문장들을 비교하여, 가장 유사한 문장을 1개 반환 \n",
    "def find_similar_sentences(base_sentence, long_text, threshold=0):\n",
    "    # 긴 텍스트를 문장으로 분리\n",
    "    sentences = nltk.sent_tokenize(long_text)\n",
    "    \n",
    "    # 유사한 문장 추출\n",
    "    base = \"\"\n",
    "    long = \"\"\n",
    "    similarity_final = 0\n",
    "    for sentence in sentences:\n",
    "        similarity = similar(base_sentence, sentence)\n",
    "        if similarity >= threshold and similarity > similarity_final:\n",
    "            base = base_sentence\n",
    "            long = sentence\n",
    "            similarity_final = similarity\n",
    "    return base, long, similarity_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num</th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Thought</th>\n",
       "      <th>Label</th>\n",
       "      <th>Refined_Thought</th>\n",
       "      <th>Cleaned_Refined_Thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm an introverted person, and I've just arriv...</td>\n",
       "      <td>Are the people in this environment unfriendly?</td>\n",
       "      <td>Overgeneralization</td>\n",
       "      <td>Sure, I can help with that. Here's a possible ...</td>\n",
       "      <td>I'm an introverted person, and I've just arriv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Recently, I feel dizzy sometimes when I stand ...</td>\n",
       "      <td>I'm so dizzy. Am I sick? I should probably go ...</td>\n",
       "      <td>No Distortion</td>\n",
       "      <td>Recently, I feel dizzy sometimes when I stand ...</td>\n",
       "      <td>Recently, I feel dizzy sometimes when I stand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm walking down the street and feel hungry, b...</td>\n",
       "      <td>I'm tired and there's no place to rest, I'm hu...</td>\n",
       "      <td>Overgeneralization</td>\n",
       "      <td>I'm walking down the street and feel hungry, b...</td>\n",
       "      <td>I'm walking down the street and feel hungry, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Work has been busy lately, but I have caught a...</td>\n",
       "      <td>Why did I catch a cold at this time? I feel so...</td>\n",
       "      <td>No Distortion</td>\n",
       "      <td>Work has been busy lately, but I have caught a...</td>\n",
       "      <td>Work has been busy lately, but I have caught a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>My mom and I are discussing future plans. She ...</td>\n",
       "      <td>Mom is trying to control my life again, wantin...</td>\n",
       "      <td>Fortune-telling</td>\n",
       "      <td>My mom and I are discussing future plans. She ...</td>\n",
       "      <td>My mom and I are discussing future plans. She ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Num                                           Scenario  \\\n",
       "0    1  I'm an introverted person, and I've just arriv...   \n",
       "1    2  Recently, I feel dizzy sometimes when I stand ...   \n",
       "2    3  I'm walking down the street and feel hungry, b...   \n",
       "3    4  Work has been busy lately, but I have caught a...   \n",
       "4    5  My mom and I are discussing future plans. She ...   \n",
       "\n",
       "                                             Thought               Label  \\\n",
       "0     Are the people in this environment unfriendly?  Overgeneralization   \n",
       "1  I'm so dizzy. Am I sick? I should probably go ...       No Distortion   \n",
       "2  I'm tired and there's no place to rest, I'm hu...  Overgeneralization   \n",
       "3  Why did I catch a cold at this time? I feel so...       No Distortion   \n",
       "4  Mom is trying to control my life again, wantin...     Fortune-telling   \n",
       "\n",
       "                                     Refined_Thought  \\\n",
       "0  Sure, I can help with that. Here's a possible ...   \n",
       "1  Recently, I feel dizzy sometimes when I stand ...   \n",
       "2  I'm walking down the street and feel hungry, b...   \n",
       "3  Work has been busy lately, but I have caught a...   \n",
       "4  My mom and I are discussing future plans. She ...   \n",
       "\n",
       "                             Cleaned_Refined_Thought  \n",
       "0  I'm an introverted person, and I've just arriv...  \n",
       "1  Recently, I feel dizzy sometimes when I stand ...  \n",
       "2  I'm walking down the street and feel hungry, b...  \n",
       "3  Work has been busy lately, but I have caught a...  \n",
       "4  My mom and I are discussing future plans. She ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv(\"data/c2d2_refined_0_500_cleaned.csv\")\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [I'm an introverted person, and I've just arri...\n",
       "1      [Recently, I feel dizzy sometimes when I stand...\n",
       "2      [I'm walking down the street and feel hungry, ...\n",
       "3      [Work has been busy lately, but I have caught ...\n",
       "4      [My mom and I are discussing future plans., Sh...\n",
       "                             ...                        \n",
       "495    [Ir parents are dissatisfied with I because I ...\n",
       "496    [When someone says I look unhappy, it's as if ...\n",
       "497    [I are pushed to the point of explosion by Ir ...\n",
       "498    [I were preparing to run for president of the ...\n",
       "499    [The takeaway order was stolen., Who is so wic...\n",
       "Name: all_Sentences, Length: 500, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw['Scenario_Sentences'] = raw['Scenario'].apply(lambda x: x.split('. '))\n",
    "raw['Scenario_Sentences'] = raw['Scenario'].apply(lambda x: nltk.sent_tokenize(x))\n",
    "raw['Thought_Sentences'] = raw['Thought'].apply(lambda x: nltk.sent_tokenize(x))\n",
    "raw['all_Sentences'] = raw['Scenario_Sentences'] + raw['Thought_Sentences']\n",
    "raw['all_Sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm walking down the street and feel hungry, but there's no restaurant around.\"]\n",
      "[\"I'm tired and there's no place to rest, I'm hungry and there's no place to eat.\", 'Why do unfortunate things always happen to me?']\n",
      "[\"I'm walking down the street and feel hungry, but there's no restaurant around.\", \"I'm tired and there's no place to rest, I'm hungry and there's no place to eat.\", 'Why do unfortunate things always happen to me?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(raw.iloc[2]['Scenario_Sentences']), print(raw.iloc[2]['Thought_Sentences']), print(raw.iloc[2]['all_Sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 결과 저장할 데이터프레임 생성\n",
    "# result_df = pd.DataFrame()\n",
    "# result_df_2 = pd.DataFrame()\n",
    "\n",
    "# # 각 행에 대해 a 컬럼의 텍스트와 b 컬럼의 문장들 간 유사도 비교\n",
    "# for index, row in raw.iterrows():\n",
    "    \n",
    "#     base_list = []\n",
    "#     long_list = []\n",
    "#     similarity_list = []\n",
    "    \n",
    "#     long_text = row['Cleaned_Refined_Thought']\n",
    "    \n",
    "#     for base_text in row['all_Sentences']:\n",
    "#         # print(base_text)\n",
    "#         base, long, similarity = find_similar_sentences(base_text, long_text)\n",
    "    \n",
    "#         base_list.append(base)\n",
    "#         long_list.append(long)\n",
    "#         similarity_list.append(similarity)\n",
    "    \n",
    "#     # 유사도가 있는 경우 평균 계산, 없으면 0으로 설정\n",
    "#     if similarity_list:\n",
    "#         average_similarity = sum(similarity_list) / len(similarity_list)\n",
    "#     else:\n",
    "#         average_similarity = 0\n",
    "        \n",
    "#     # 데이터프레임으로 만들어서 비교\n",
    "#     result = pd.DataFrame({\n",
    "#         'base': [base_list],\n",
    "#         'long': [long_list],\n",
    "#         'similarity': [similarity_list],\n",
    "#         'average_similarity': average_similarity\n",
    "#     })\n",
    "    \n",
    "#     result_df = pd.concat([result_df, result], ignore_index=True)\n",
    "    \n",
    "#     # 데이터프레임으로 만들어서 비교 (threshold 비교하기 쉽게 만든 버전)\n",
    "#     result_2 = pd.DataFrame({\n",
    "#         'base': base_list,\n",
    "#         'long': long_list,\n",
    "#         'similarity': similarity_list,\n",
    "#         'average_similarity': average_similarity\n",
    "#     })\n",
    "    \n",
    "#     result_df_2 = pd.concat([result_df_2, result_2], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceSimilarity:\n",
    "    def __init__(self, raw_data, story_text_col_nm):\n",
    "        self.raw = raw_data\n",
    "        self.result_df = pd.DataFrame()\n",
    "        self.result_df_2 = pd.DataFrame()\n",
    "        self.find_similar_sentences = find_similar_sentences\n",
    "        self.story_text_col_nm = story_text_col_nm\n",
    "    \n",
    "    def calculate_similarity(self):\n",
    "        for index, row in self.raw.iterrows():\n",
    "            base_list = []\n",
    "            long_list = []\n",
    "            similarity_list = []\n",
    "\n",
    "            long_text = row[self.story_text_col_nm]\n",
    "\n",
    "            for base_text in row['all_Sentences']:\n",
    "                base, long, similarity = self.find_similar_sentences(base_text, long_text)\n",
    "\n",
    "                base_list.append(base)\n",
    "                long_list.append(long)\n",
    "                similarity_list.append(similarity)\n",
    "\n",
    "            # 유사도가 있는 경우 평균 계산, 없으면 0으로 설정\n",
    "            if similarity_list:\n",
    "                average_similarity = sum(similarity_list) / len(similarity_list)\n",
    "            else:\n",
    "                average_similarity = 0\n",
    "\n",
    "            # 결과 저장 (result_df)\n",
    "            result = pd.DataFrame({\n",
    "                'base': [base_list],\n",
    "                'long': [long_list],\n",
    "                'similarity': [similarity_list],\n",
    "                'average_similarity': average_similarity\n",
    "            })\n",
    "            self.result_df = pd.concat([self.result_df, result], ignore_index=True)\n",
    "\n",
    "            # 결과 저장 (result_df_2, threshold 비교하기 쉽게 만든 버전)\n",
    "            result_2 = pd.DataFrame({\n",
    "                'base': base_list,\n",
    "                'long': long_list,\n",
    "                'similarity': similarity_list,\n",
    "                'average_similarity': average_similarity\n",
    "            })\n",
    "            self.result_df_2 = pd.concat([self.result_df_2, result_2], ignore_index=True)\n",
    "\n",
    "    def get_results(self):\n",
    "        return self.result_df, self.result_df_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 인스턴스 생성\n",
    "similarity_checker = SentenceSimilarity(raw, 'Cleaned_Refined_Thought')\n",
    "\n",
    "# 유사도 계산 실행\n",
    "similarity_checker.calculate_similarity()\n",
    "\n",
    "# 결과 가져오기\n",
    "result_df, result_df_2 = similarity_checker.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  base  \\\n",
      "0    [I'm an introverted person, and I've just arri...   \n",
      "1    [Recently, I feel dizzy sometimes when I stand...   \n",
      "2    [I'm walking down the street and feel hungry, ...   \n",
      "3    [Work has been busy lately, but I have caught ...   \n",
      "4    [My mom and I are discussing future plans., Sh...   \n",
      "..                                                 ...   \n",
      "495  [Ir parents are dissatisfied with I because I ...   \n",
      "496  [When someone says I look unhappy, it's as if ...   \n",
      "497  [I are pushed to the point of explosion by Ir ...   \n",
      "498  [I were preparing to run for president of the ...   \n",
      "499  [The takeaway order was stolen., Who is so wic...   \n",
      "\n",
      "                                                  long  \\\n",
      "0    [I'm an introverted person, and I've just arri...   \n",
      "1    [Recently, I feel dizzy sometimes when I stand...   \n",
      "2    [I'm walking down the street and feel hungry, ...   \n",
      "3    [Work has been busy lately, but I have caught ...   \n",
      "4    [My mom and I are discussing future plans., Sh...   \n",
      "..                                                 ...   \n",
      "495  [My parents are dissatisfied with me because I...   \n",
      "496  [When someone says I look unhappy, it's as if ...   \n",
      "497  [I are pushed to the point of explosion by my ...   \n",
      "498  [I were preparing to run for president of the ...   \n",
      "499  [The takeaway order was stolen., Who is so wic...   \n",
      "\n",
      "                                   similarity  average_similarity  \n",
      "0                                  [1.0, 1.0]            1.000000  \n",
      "1                        [1.0, 1.0, 1.0, 1.0]            1.000000  \n",
      "2                             [1.0, 1.0, 1.0]            1.000000  \n",
      "3    [1.0, 1.0, 1.0, 1.0, 0.6129032258064516]            0.922581  \n",
      "4                        [1.0, 1.0, 1.0, 1.0]            1.000000  \n",
      "..                                        ...                 ...  \n",
      "495                 [0.9548387096774194, 1.0]            0.977419  \n",
      "496                    [0.976, 1.0, 1.0, 1.0]            0.994000  \n",
      "497            [0.9809523809523809, 1.0, 1.0]            0.993651  \n",
      "498                      [1.0, 1.0, 1.0, 1.0]            1.000000  \n",
      "499                           [1.0, 1.0, 1.0]            1.000000  \n",
      "\n",
      "[500 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 저장\n",
    "result_df.to_csv('data/Sentence_similarity_comparison.csv', index=False)\n",
    "result_df_2.to_csv('data/Sentence_similarity_comparison_easy.csv', index=False)\n",
    "\n",
    "# 결과를 raw 데이터프레임에 추가\n",
    "raw['base'] = result_df['base']\n",
    "raw['long'] = result_df['long']\n",
    "raw['similarity'] = result_df['similarity']\n",
    "raw['average_similarity'] = result_df['average_similarity']\n",
    "\n",
    "raw.to_csv('data/c2d2_0_500_similarity.csv', index=False)\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mete를 이용해 생성한 데이터도 확인\n",
    "- 잘 모르겠다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>persona</th>\n",
       "      <th>pattern</th>\n",
       "      <th>pattern_def</th>\n",
       "      <th>thought</th>\n",
       "      <th>scenario</th>\n",
       "      <th>persona_in_scenario</th>\n",
       "      <th>thought_in_scenario</th>\n",
       "      <th>Refined_Thought</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have a pencil thin mustache . i have six tat...</td>\n",
       "      <td>Catastrophizing</td>\n",
       "      <td>Catastrophizing: Giving greater weight to the ...</td>\n",
       "      <td>I like my cats. I think one day they will plot...</td>\n",
       "      <td>i have a pencil thin mustache . i have six tat...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Sure, I can help you with that. Here's a recon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i like visiting art museums in my spare time ....</td>\n",
       "      <td>Overgeneralization</td>\n",
       "      <td>Someone who overgeneralizes makes faulty gener...</td>\n",
       "      <td>I'm a vegan, and the restaurant served me a di...</td>\n",
       "      <td>i like visiting art museums in my spare time ....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Sure, I understand. Here is the completed diar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i like to train dogs . i like to make cookies ...</td>\n",
       "      <td>Jumping to conclusions: mind reading</td>\n",
       "      <td>Inferring a person's possible or probable (usu...</td>\n",
       "      <td>The cashier at the bagel store messed up my or...</td>\n",
       "      <td>i like to train dogs . i like to make cookies ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Sure, here is a possible continuation of your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i like to eat tune . i've two cats . i like to...</td>\n",
       "      <td>Black-and-white or polarized thinking / All or...</td>\n",
       "      <td>Looking at life in all-or-nothing categories. ...</td>\n",
       "      <td>One of my cats is sick so I'll never adopt ano...</td>\n",
       "      <td>i like to eat tune . i've two cats . i like to...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Sure, here's the diary entry with additional s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i like visiting art museums in my spare time ....</td>\n",
       "      <td>Jumping to conclusions: Fortune-telling</td>\n",
       "      <td>Predicting outcomes (usually negative) of events.</td>\n",
       "      <td>My new boyfriend is going to dump me once they...</td>\n",
       "      <td>i like visiting art museums in my spare time ....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>My new boyfriend is going to dump me once they...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             persona  \\\n",
       "0  i have a pencil thin mustache . i have six tat...   \n",
       "1  i like visiting art museums in my spare time ....   \n",
       "2  i like to train dogs . i like to make cookies ...   \n",
       "3  i like to eat tune . i've two cats . i like to...   \n",
       "4  i like visiting art museums in my spare time ....   \n",
       "\n",
       "                                             pattern  \\\n",
       "0                                    Catastrophizing   \n",
       "1                                 Overgeneralization   \n",
       "2               Jumping to conclusions: mind reading   \n",
       "3  Black-and-white or polarized thinking / All or...   \n",
       "4            Jumping to conclusions: Fortune-telling   \n",
       "\n",
       "                                         pattern_def  \\\n",
       "0  Catastrophizing: Giving greater weight to the ...   \n",
       "1  Someone who overgeneralizes makes faulty gener...   \n",
       "2  Inferring a person's possible or probable (usu...   \n",
       "3  Looking at life in all-or-nothing categories. ...   \n",
       "4  Predicting outcomes (usually negative) of events.   \n",
       "\n",
       "                                             thought  \\\n",
       "0  I like my cats. I think one day they will plot...   \n",
       "1  I'm a vegan, and the restaurant served me a di...   \n",
       "2  The cashier at the bagel store messed up my or...   \n",
       "3  One of my cats is sick so I'll never adopt ano...   \n",
       "4  My new boyfriend is going to dump me once they...   \n",
       "\n",
       "                                            scenario  persona_in_scenario  \\\n",
       "0  i have a pencil thin mustache . i have six tat...                 True   \n",
       "1  i like visiting art museums in my spare time ....                 True   \n",
       "2  i like to train dogs . i like to make cookies ...                 True   \n",
       "3  i like to eat tune . i've two cats . i like to...                 True   \n",
       "4  i like visiting art museums in my spare time ....                 True   \n",
       "\n",
       "   thought_in_scenario                                    Refined_Thought  \n",
       "0                 True  Sure, I can help you with that. Here's a recon...  \n",
       "1                 True  Sure, I understand. Here is the completed diar...  \n",
       "2                 True  Sure, here is a possible continuation of your ...  \n",
       "3                 True  Sure, here's the diary entry with additional s...  \n",
       "4                 True  My new boyfriend is going to dump me once they...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv(\"data/meta_refined01.csv\")\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [I like my cats., I think one day they will pl...\n",
       "1       [I'm a vegan, and the restaurant served me a d...\n",
       "2       [The cashier at the bagel store messed up my o...\n",
       "3       [One of my cats is sick so I'll never adopt an...\n",
       "4       [My new boyfriend is going to dump me once the...\n",
       "                              ...                        \n",
       "1721    [I have an appointment with Jim's dog Sparky t...\n",
       "1722    [My performance in the church choir was praise...\n",
       "1723    [I hiked in the past on the Appalachian trials...\n",
       "1724    [I have four siblings and one of them was mean...\n",
       "1725    [I found a new spot to get hamburgers., I'm th...\n",
       "Name: all_Sentences, Length: 1726, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['all_Sentences'] = raw['thought'].apply(lambda x: nltk.sent_tokenize(x))\n",
    "raw['all_Sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 인스턴스 생성\n",
    "similarity_checker = SentenceSimilarity(raw, 'Refined_Thought')\n",
    "\n",
    "# 유사도 계산 실행\n",
    "similarity_checker.calculate_similarity()\n",
    "\n",
    "# 결과 가져오기\n",
    "result_df, result_df_2 = similarity_checker.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   base  \\\n",
      "0     [I like my cats., I think one day they will pl...   \n",
      "1     [I'm a vegan, and the restaurant served me a d...   \n",
      "2     [The cashier at the bagel store messed up my o...   \n",
      "3     [One of my cats is sick so I'll never adopt an...   \n",
      "4     [My new boyfriend is going to dump me once the...   \n",
      "...                                                 ...   \n",
      "1721  [I have an appointment with Jim's dog Sparky t...   \n",
      "1722  [My performance in the church choir was praise...   \n",
      "1723  [I hiked in the past on the Appalachian trials...   \n",
      "1724  [I have four siblings and one of them was mean...   \n",
      "1725  [I found a new spot to get hamburgers., I'm th...   \n",
      "\n",
      "                                                   long  \\\n",
      "0     [Here's a reconstructed version of the diary e...   \n",
      "1     [I'm a vegan, and the restaurant served me a d...   \n",
      "2     [The cashier at the bagel store messed up my o...   \n",
      "3     [One of my cats is sick so I'll never adopt an...   \n",
      "4     [My new boyfriend is going to dump me once the...   \n",
      "...                                                 ...   \n",
      "1721  [I have an appointment with Jim's dog Sparky t...   \n",
      "1722  [My performance in the church choir was praise...   \n",
      "1723  [I hiked in the past on the Appalachian trails...   \n",
      "1724  [I have four siblings and one of them was mean...   \n",
      "1725  [Here is your revised journal entry:\\n\\nI foun...   \n",
      "\n",
      "                                     similarity  average_similarity  \n",
      "0     [0.26785714285714285, 0.6565656565656566]            0.462211  \n",
      "1                                    [1.0, 1.0]            1.000000  \n",
      "2                                    [1.0, 1.0]            1.000000  \n",
      "3                                         [1.0]            1.000000  \n",
      "4                                         [1.0]            1.000000  \n",
      "...                                         ...                 ...  \n",
      "1721                                 [1.0, 1.0]            1.000000  \n",
      "1722                                      [1.0]            1.000000  \n",
      "1723                        [0.987012987012987]            0.987013  \n",
      "1724                       [0.9894736842105263]            0.989474  \n",
      "1725   [0.6666666666666666, 0.9917355371900827]            0.829201  \n",
      "\n",
      "[1726 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# 저장\n",
    "result_df.to_csv('data/meta_Sentence_similarity_comparison.csv', index=False)\n",
    "result_df_2.to_csv('data/meat_Sentence_similarity_comparison_easy.csv', index=False)\n",
    "\n",
    "# 결과를 raw 데이터프레임에 추가\n",
    "raw['base'] = result_df['base']\n",
    "raw['long'] = result_df['long']\n",
    "raw['similarity'] = result_df['similarity']\n",
    "raw['average_similarity'] = result_df['average_similarity']\n",
    "\n",
    "raw.to_csv('data/meta_similarity.csv', index=False)\n",
    "\n",
    "print(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
