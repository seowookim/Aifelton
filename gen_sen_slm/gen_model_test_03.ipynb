{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 아이펠톤에서 사용할 텍스트 생성 모델 테스트\n",
    "\n",
    "- 241009 text 생성 다시 테스트\n",
    "- [survay 논문](https://discuss.pytorch.kr/t/llm-synthetic-data-survey/4764/1) 참고함\n",
    "\n",
    "## 코드 흐름\n",
    "- 아래 정보가 적혀 있는 구글 스프레드 시트 가져옴\n",
    "    - 모델 선택\n",
    "    - 파라미터 선택\n",
    "    - 생성할 텍스트 개수 선택\n",
    "    - 인지 왜곡 문장 선택\n",
    "    - 인지 왜곡 class 선택\n",
    "    - 인지 왜곡 몇개 예시로 줄지 선택 \n",
    "    - 프롬프트 입력\n",
    "- 벤치마킹 데이터에서 인지 왜곡 class와 같은 데이터 가져옴\n",
    "- 최종 프롬프트 생성\n",
    "- text gen\n",
    "- 구글스프레드 시트에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saink\\py_purpose\\hugginhface\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import gspread, os\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import random\n",
    "import math\n",
    "import re \n",
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA가 사용 가능한지 확인하여 device 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 출력해서 현재 선택된 device 확인\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "# .env 파일에서 Hugging Face 토큰 불러오기\n",
    "token = os.getenv('HUGGINGFACE_TOKEN')\n",
    "\n",
    "# 번역기 초기화\n",
    "translator = GoogleTranslator(source='auto', target='ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글 API 사용을 위한 상수들\n",
    "scope = ['https://spreadsheets.google.com/feeds',\n",
    "         'https://www.googleapis.com/auth/drive']\n",
    "key_file_name = 'aiffelthon-438107-8b246f7e616c.json' # 아까 받은 json 인증키 파일 경로가 들어가면 됨.\n",
    "\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(key_file_name, scope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model_name  max_new_tokens temperature top_p top_k  \\\n",
      "41  Qwen/Qwen2.5-7B-Instruct            1024         0.8   0.8    50   \n",
      "42  Qwen/Qwen2.5-7B-Instruct            1024         0.8   0.8    50   \n",
      "43  Qwen/Qwen2.5-7B-Instruct            1024         0.8   0.8    50   \n",
      "\n",
      "   repetition_penalty  gen_num  example_num  \\\n",
      "41                1.2        5            2   \n",
      "42                1.2        5            0   \n",
      "43                1.2        5            2   \n",
      "\n",
      "                                            prompt_01  \\\n",
      "41  Suppose you are a patient receiving psychologi...   \n",
      "42  Suppose you are a patient receiving psychologi...   \n",
      "43  Suppose you are a patient receiving psychologi...   \n",
      "\n",
      "                                            prompt_02  \\\n",
      "41                                                      \n",
      "42  1. It should be between 30 and 80 words in length   \n",
      "43  1. It should be between 30 and 80 words in length   \n",
      "\n",
      "                                            prompt_03 prompt_04 prompt_05  \\\n",
      "41                                                                          \n",
      "42  2. The writing should convey a sense of {emoti...                       \n",
      "43  2. The writing should convey a sense of {emoti...                       \n",
      "\n",
      "   prompt_06 prompt_07 prompt_08 prompt_09 prompt_10 prompt_11  \\\n",
      "41                                                               \n",
      "42                                                               \n",
      "43                                                               \n",
      "\n",
      "              prompt_12  \n",
      "41  Here is an example:  \n",
      "42                       \n",
      "43  Here is an example:  \n"
     ]
    }
   ],
   "source": [
    "spreadsheet = gspread.authorize(credentials).open(\"prompt\")\n",
    "worksheet = spreadsheet.worksheet(\"test02\")\n",
    "# worksheet = spreadsheet.worksheet(\"tmp\")\n",
    "resultsheet = spreadsheet.worksheet(\"test02_re\")\n",
    "\n",
    "# 스프레드시트 데이터를 가져와 데이터프레임으로 변환\n",
    "data = worksheet.get_all_records()\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# gen_num = 0 인 것 제거\n",
    "worksheet_df = df[df['gen_num'] != 0]\n",
    "\n",
    "# 데이터프레임의 마지막 3개 row 출력\n",
    "print(worksheet_df.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 가져오기\n",
    "## 파일 이름\n",
    "raw_filename = 'raw_data/meta0911.csv'\n",
    "benchmark_filename = 'raw_data/Annotated_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['persona', 'pattern', 'pattern_def', 'thought', 'scenario',\n",
      "       'persona_in_scenario', 'thought_in_scenario'],\n",
      "      dtype='object')\n",
      "--------------------------\n",
      "Index(['Id_Number', 'Patient Question', 'Distorted part',\n",
      "       'Dominant Distortion', 'Secondary Distortion (Optional)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "meta_data = pd.read_csv(raw_filename, encoding='latin1')\n",
    "print(meta_data.columns)\n",
    "print(\"--------------------------\")\n",
    "\n",
    "benchmark_data = pd.read_csv(benchmark_filename)\n",
    "print(benchmark_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern\n",
      "Magnification              200\n",
      "Fortune-telling            199\n",
      "Overgeneralization         197\n",
      "Mind Reading               197\n",
      "Labeling                   196\n",
      "All-or-nothing thinking    188\n",
      "Personalization            185\n",
      "Mental filter              185\n",
      "Should statements          179\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "## meta 데이터의 class 이름이 다른 부분 똑같이 맞추기\n",
    "meta_data['pattern'] = meta_data['pattern'].replace('Mental filtering', 'Mental filter')\n",
    "meta_data['pattern'] = meta_data['pattern'].replace('Labeling and mislabeling', 'Labeling')\n",
    "meta_data['pattern'] = meta_data['pattern'].replace('Jumping to conclusions: mind reading', 'Mind Reading')\n",
    "meta_data['pattern'] = meta_data['pattern'].replace('Jumping to conclusions: Fortune-telling', 'Fortune-telling')\n",
    "meta_data['pattern'] = meta_data['pattern'].replace('Catastrophizing', 'Magnification')\n",
    "meta_data['pattern'] = meta_data['pattern'].replace('Black-and-white or polarized thinking / All or nothing thinking', 'All-or-nothing thinking')\n",
    "\n",
    "# 개수 확인\n",
    "print(meta_data['pattern'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominant Distortion\n",
      "No Distortion              933\n",
      "Mind Reading               199\n",
      "Overgeneralization         187\n",
      "Magnification              145\n",
      "Personalization            104\n",
      "Fortune-telling            102\n",
      "Labeling                   102\n",
      "Emotional Reasoning         98\n",
      "Should statements           86\n",
      "Mental filter               81\n",
      "All-or-nothing thinking     77\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# benchmark 데이터에서 Secondary Distortion (Optional) 컬럼에 값 있는 것 제외\n",
    "benchmark_data = benchmark_data[benchmark_data['Secondary Distortion (Optional)'].isnull()]\n",
    "\n",
    "# 개수 확인\n",
    "print(benchmark_data['Dominant Distortion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양성을 주기 위한 감정 리스트\n",
    "emtion_list = ['Depression', 'anger', 'anxiety', 'disappointment', 'helplessness']\n",
    "\n",
    "# 인지왜곡 정의 \n",
    "definition_dict = {\n",
    "    \"Emotional Reasoning\": \"Believing 'I feel that way, so it must be true'.\",\n",
    "    \"Overgeneralization\": \"Drawing conclusions with limited and often un negative experience.\",\n",
    "    \"Mental Filter\": \"Focusing only on limited negative aspects and not the excessive positive ones.\",\n",
    "    \"Should Statements\": \"Expecting things or personal behavior should be a certain way.\",\n",
    "    \"All-or-nothing thinking\": \"Binary thought pattern. Considering anything short of perfection as a failure.\",\n",
    "    \"Mind Reading\": \"Concluding that others are reacting negatively to you, without any basis in fact.\",\n",
    "    \"Fortune-telling\": \"Predicting that an event will always result in the worst possible outcome.\",\n",
    "    \"Magnification\": \"Exaggerating or Catastrophizing the outcome of certain events or behavior.\",\n",
    "    \"Personalization\": \"Holding oneself personally responsible for events beyond one’s control.\",\n",
    "    \"Labeling\": \"Attaching labels to oneself or others (ex: 'loser', 'perfect').\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 행에 대해 prompt 문자열을 result 문자열에서 제거하는 함수 정의\n",
    "def remove_prompt_from_result(row):\n",
    "    prompt = row['prompt']\n",
    "    result = row['result']\n",
    "    \n",
    "    # prompt 문자열을 result 문자열에서 제거\n",
    "    cleaned_result = result.replace(prompt, \"\").strip()\n",
    "    \n",
    "    # prompt의 마지막 문장을 추출\n",
    "    last_sentence = prompt.split('. ')[-1].strip() if '.' in prompt else prompt\n",
    "    \n",
    "    # 문장별로 나눔    \n",
    "    sentences = re.split(r'(?<=[.!?]) +', cleaned_result)\n",
    "    \n",
    "    # B가 나타나는 문장을 찾고, 그 위치까지의 문장을 제거\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if last_sentence in sentence:\n",
    "            # B가 포함된 문장까지를 제거한 나머지 문장을 결합\n",
    "            remaining_sentences = sentences[i+1:]\n",
    "            cleaned_result = ' '.join(remaining_sentences).strip()\n",
    "    \n",
    "    return cleaned_result\n",
    "\n",
    "def translate_text(text):\n",
    "    # 텍스트를 5000자 이하의 청크로 나누기\n",
    "    max_length = 3000\n",
    "    chunks = [text[i:i + max_length] for i in range(0, len(text), max_length)]\n",
    "    \n",
    "    # 각 청크를 번역하고 결과를 합치기\n",
    "    translated_chunks = [translator.translate(chunk) for chunk in chunks]\n",
    "    return ''.join(translated_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "previouse_model_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "Suppose you are a patient receiving psychological counseling. Write a response to the question, \"Did something happen yesterday?\"\n",
      "--------------------------\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "Suppose you are a patient receiving psychological counseling. Write a 3-7 sentence response to the question, \"Did something happen yesterday?\"\n",
      "--------------------------\n",
      "Suppose you are a patient receiving psychological counseling.\n",
      "Generate a piece of writing. The writing should include the following elements;\n",
      "--------------------------\n",
      "Suppose you are a patient receiving psychological counseling.\n",
      "Generate a piece of writing. The writing should include the following elements:\n",
      "--------------------------\n",
      "Suppose you are a patient receiving psychological counseling.\n",
      "Generate a piece of writing. The writing should include the following elements:\n",
      "--------------------------\n",
      "Suppose you are a patient receiving psychological counseling. Write about a situation you experienced, including the sentence \"{sentence}.\" The writing should strongly exhibit cognitive distortion of {cognitive_distortion_class} and convey a sense of {emotion} throughout.\n",
      "\n",
      "--------------------------\n",
      "Suppose you are a patient receiving psychological counseling. Write about a situation you experienced, including the sentence \"{sentence}.\" The writing should strongly exhibit cognitive distortion of {cognitive_distortion_class} and convey a sense of {emotion} throughout.\n",
      "\n",
      "--------------------------\n",
      "Suppose you are a patient receiving psychological counseling. Write about a situation you experienced, including the sentence \"{sentence}.\" The writing should strongly exhibit cognitive distortion of {cognitive_distortion_class}. following the requirements below:\n",
      "1. It should be between 30 and 80 words in length\n",
      "--------------------------\n",
      "Suppose you are a patient receiving psychological counseling. Write about a situation you experienced, including the sentence \"{sentence}.\" The writing should strongly exhibit cognitive distortion of {cognitive_distortion_class}. following the requirements below:\n",
      "1. It should be between 30 and 80 words in length\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for index, row in worksheet_df.iterrows():\n",
    "    # print(row)\n",
    "    \n",
    "    # 모델 로드, 이전과 다른 모델이여야 로드함\n",
    "    model_name = row['model_name']\n",
    "    \n",
    "    # if previouse_model_name != model_name:\n",
    "    #     try:\n",
    "    #         # 모델과 토크나이저 로드 및 pad_token_id 설정\n",
    "    #         tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    #         model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "            \n",
    "    #         # pad_token_id가 설정되지 않았다면 eos_token_id로 설정\n",
    "    #         if model.config.pad_token_id is None:\n",
    "    #             model.config.pad_token_id = tokenizer.eos_token_id\n",
    "            \n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Failed to load model: {model_name}. Error: {str(e)}\")\n",
    "    #         resultsheet.append_row(row.tolist(), table_range='A1') # Google 스프레드시트에 새로운 행 추가\n",
    "    #         continue\n",
    "    \n",
    "    # previouse_model_name = model_name\n",
    "    \n",
    "    # --------------------------------------------------- #\n",
    "    \n",
    "    # 파라미터 가져오기\n",
    "    params = {\n",
    "        'max_new_tokens': int(row['max_new_tokens']) if pd.notna(row['max_new_tokens']) and row['max_new_tokens'] != '' else None,\n",
    "        'temperature': row['temperature'] if pd.notna(row['temperature']) and row['temperature'] != '' else None,\n",
    "        'top_p': row['top_p'] if pd.notna(row['top_p']) and row['top_p'] != '' else None,\n",
    "        'top_k': int(row['top_k']) if pd.notna(row['top_k']) and row['top_k'] != '' else None,\n",
    "        'repetition_penalty': row['repetition_penalty'] if pd.notna(row['repetition_penalty']) and row['repetition_penalty'] != '' else None\n",
    "    }\n",
    "\n",
    "    # None 값을 제거하여 기본값을 사용하게 함\n",
    "    params = {k: v for k, v in params.items() if v is not None}\n",
    "\n",
    "    # --------------------------------------------------- #\n",
    "\n",
    "    # 프롬프트 생성\n",
    "    # prompt_01부터 prompt_12까지의 컬럼 값을 줄바꿈 형식으로 합치기\n",
    "    raw_prompt = '\\n'.join(row[f'prompt_{i:02d}'] for i in range(1, 13) if worksheet_df.iloc[0][f'prompt_{i:02d}'])\n",
    "    print(raw_prompt)\n",
    "    print(\"--------------------------\")\n",
    "        \n",
    "    # # 생성할 개수\n",
    "    # gen_num = int(row['gen_num'])\n",
    "\n",
    "    # # 생성 시작\n",
    "    # for which in range(gen_num):\n",
    "    #     print(which)\n",
    "        \n",
    "    #     # 각 반복마다 prompt 초기화\n",
    "    #     prompt = raw_prompt  # 이 부분이 반복문 내부로 이동되었습니다.\n",
    "        \n",
    "    #     emotion_num = len(emtion_list)\n",
    "    #     data_row = math.ceil(which/emotion_num)\n",
    "        \n",
    "    #     # 사용할 인지왜곡 문장\n",
    "    #     distorted_thought = meta_data['thought'].iloc[data_row]\n",
    "    #     print(distorted_thought)\n",
    "\n",
    "    #     # 위 인지왜곡 문장의 class\n",
    "    #     distorted_class = meta_data['pattern'].iloc[data_row]\n",
    "    #     print(distorted_class)\n",
    "        \n",
    "    #     # 위 인지왜곡 class에 해당하는 정의\n",
    "    #     definition = definition_dict.get(distorted_class)\n",
    "        \n",
    "    #     # 다양성을 주기 위한 감정 추가\n",
    "    #     emotion = emtion_list[which % emotion_num]\n",
    "    \n",
    "    #     # 예시 추가\n",
    "    #     # 추가할 예시 문장 개수\n",
    "    #     prompt_num = int(row['example_num'])\n",
    "        \n",
    "    #     filtered_data = benchmark_data[benchmark_data['Dominant Distortion'] == distorted_class]['Patient Question'].dropna().tolist()\n",
    "        \n",
    "    #     # 랜덤하게 num_samples 개수만큼 선택\n",
    "    #     samples = random.sample(filtered_data, min(prompt_num, len(filtered_data)))\n",
    "        \n",
    "    #     for i, sample in enumerate(samples, 1):\n",
    "    #         prompt += f\"\\nExample {i}: {sample}\"\n",
    "                        \n",
    "    #     prompt = prompt.format(emotion=emotion, sentence=distorted_thought, definition=definition, cognitive_distortion_class = distorted_class)\n",
    "    #     print(f\"Prompt: {prompt}\")\n",
    "        \n",
    "    #     try:\n",
    "    #         start_time = time.time() # 시작 시간 기록\n",
    "            \n",
    "    #         # 입력을 토큰화하고 attention_mask 추가\n",
    "    #         inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "                            \n",
    "    #         # 결과 생성\n",
    "    #         with torch.no_grad():\n",
    "    #             result = model.generate(\n",
    "    #                 inputs['input_ids'], \n",
    "    #                 attention_mask=inputs['attention_mask'],  # attention_mask 추가\n",
    "    #                 pad_token_id=model.config.pad_token_id,  # pad_token_id 추가\n",
    "    #                 **params\n",
    "    #             )\n",
    "                \n",
    "    #         # 생성된 텍스트 디코딩\n",
    "    #         result = tokenizer.decode(result[0], skip_special_tokens=True)\n",
    "    #         end_time = time.time() # 종료 시간 기록\n",
    "            \n",
    "    #         row['prompt'] = prompt  # 생성된 프롬프트 저장\n",
    "    #         row['result'] = result  # 생성된 결과 저장\n",
    "    #         row['time'] = round(end_time - start_time, 0) # 실행 시간 저장\n",
    "            \n",
    "    #         # 'cleaned result' 열 추가\n",
    "    #         row['cleaned result'] = remove_prompt_from_result(row)\n",
    "\n",
    "    #         # 'cleaned result' 열을 번역하여 'trans result' 열 생성\n",
    "    #         row['trans result'] = translate_text(row['cleaned result'])\n",
    "            \n",
    "    #         resultsheet.append_row(row.tolist(), table_range='A1') # Google 스프레드시트에 새로운 행 추가\n",
    "            \n",
    "    #         gc.collect()\n",
    "    #         torch.cuda.empty_cache()\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"Error: {e}\")\n",
    "    #         resultsheet.append_row(row.tolist(), table_range='A1') # Google 스프레드시트에 새로운 행 추가\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
